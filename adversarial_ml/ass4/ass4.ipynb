{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LITlOhWFMaf"
   },
   "source": [
    "##Get The data and process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CvOwkHVaFF03",
    "outputId": "f5eb3123-9505-402a-fecf-42f07049e106"
   },
   "outputs": [],
   "source": [
    "# mount google drive on your runtime using and authorization code.\n",
    "# more details here: https://colab.research.google.com/notebooks/io.ipynb\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68YtrFxbFXdh"
   },
   "source": [
    "#some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UtwPTRKaFTMK"
   },
   "outputs": [],
   "source": [
    "# import library\n",
    "#You will need to add yours\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pickle\n",
    "#import os\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from art.attacks.poisoning.perturbations import add_pattern_bd, add_single_bd, insert_image\n",
    "\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "from imutils import paths\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTUkUQ7MFYqO"
   },
   "source": [
    "#Path to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wqiIetRtF8AY"
   },
   "outputs": [],
   "source": [
    "# Path to the directory containing the your project info (Change to your location)\n",
    "PROJECT_ROOT_DIR = '/content/drive/MyDrive/CS5331_CS4331_Fa24/img/'\n",
    "\n",
    "# Path to the directory containing the dataset\n",
    "# DOWNLOAD BUSI dataset here: https://scholar.cu.edu.eg/?q=afahmy/pages/dataset\n",
    "DATA_DIR = 'Dataset_BUSI_with_GT/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCKIjI4fFbtq"
   },
   "source": [
    "#loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mjYED0feHUYZ"
   },
   "outputs": [],
   "source": [
    "# Funciton for loading the dataset\n",
    "# reference: https://www.pyimagesearch.com/2018/09/10/keras-tutorial-how-to-get-started-with-keras-deep-learning-and-python/\n",
    "def load_image():\n",
    "  # initialize the data and labels for each class\n",
    "  data = []\n",
    "  labels = []\n",
    "\n",
    "  data_aside = []\n",
    "  labels_aside = []\n",
    "\n",
    "  benign_data = []\n",
    "  benign_labels = []\n",
    "\n",
    "  malignant_data = []\n",
    "  malignant_labels = []\n",
    "\n",
    "  normal_data = []\n",
    "  normal_labels = []\n",
    "\n",
    "  # load benign image\n",
    "  for i in range(1,438):\n",
    "    image = cv2.imread(PROJECT_ROOT_DIR + DATA_DIR + 'benign/' + 'benign (' + str(i) + ').png')\n",
    "    # resize image to 224 * 224 * 3\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    benign_data.append(image)\n",
    "    # extract the class label from the image folder\n",
    "    benign_labels.append('benign')\n",
    "\n",
    "  for i in range(0,437):\n",
    "      data.append(benign_data[i])\n",
    "      labels.append(benign_labels[i])\n",
    "\n",
    "  # load malignant image\n",
    "  for i in range(1,211):\n",
    "    image = cv2.imread(PROJECT_ROOT_DIR + DATA_DIR + 'malignant/' + 'malignant (' + str(i) + ').png')\n",
    "    # resize image to 224 * 224 * 3\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    malignant_data.append(image)\n",
    "    # extract the class label from the image folder\n",
    "    malignant_labels.append('malignant')\n",
    "\n",
    "  for i in range(0,210):\n",
    "      data.append(malignant_data[i])\n",
    "      labels.append(malignant_labels[i])\n",
    "\n",
    "  # load normal image\n",
    "  for i in range(1,134):\n",
    "    image = cv2.imread(PROJECT_ROOT_DIR + DATA_DIR + 'normal/' + 'normal (' + str(i) + ').png')\n",
    "    # resize image to 224 * 224 * 3\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    normal_data.append(image)\n",
    "    # extract the class label from the image folder\n",
    "    normal_labels.append('normal')\n",
    "\n",
    "  for i in range(0,133):\n",
    "      data.append(normal_data[i])\n",
    "      labels.append(normal_labels[i])\n",
    "\n",
    "  return data, labels\n",
    "# Function for image preprocessing\n",
    "def preprocess(data,labels):\n",
    "  # Save training and test image to numpy, Scale image features to be in [0, 1]\n",
    "  data = np.array(data, dtype = np.float32) / 255.0\n",
    "  # Save labels to numpy encode label to integer catergory 0 = 'benign', 1 = 'malignant', 2 = 'normal'\n",
    "  labels = np.array(labels)\n",
    "  new_label_encoder = preprocessing.LabelEncoder()\n",
    "  new_label_encoder.fit(labels)\n",
    "  targets = new_label_encoder.transform(labels)\n",
    "\n",
    "  return data, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-hF5jQ-6HaWM"
   },
   "outputs": [],
   "source": [
    "# Load the BUSI images and labels\n",
    "# This will take time (my time was around 12 min)\n",
    "data, labels = load_image()\n",
    "data, labels = preprocess(data,labels)\n",
    "\n",
    "# split data into 80% train and 20% test, shuffle the data with\n",
    "(imgs_train, imgs_test, labels_train, labels_test) = train_test_split(data, labels, test_size = 0.2, random_state=42, shuffle = True)\n",
    "# split data into 60% train data and 20% validation data\n",
    "(imgs_train, imgs_val, labels_train, labels_val) = train_test_split(imgs_train, labels_train, test_size = 0.2, random_state=42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_PVU-E5AHm03",
    "outputId": "2130fefd-3651-4858-c81a-f238afbee247"
   },
   "outputs": [],
   "source": [
    "# Display the shapes of train, validation, and test datasets\n",
    "print('Images train shape: {} - Labels train shape: {}'.format(imgs_train.shape, labels_train.shape))\n",
    "print('Images validation shape: {} - Labels validation shape: {}'.format(imgs_val.shape, labels_val.shape))\n",
    "print('Images test shape: {} - Labels test shape: {}'.format(imgs_test.shape, labels_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ry52SNv4Fgch"
   },
   "source": [
    "## Set constants and convert labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4JbwRwqIIFDh"
   },
   "outputs": [],
   "source": [
    "## Set constants\n",
    "NUM_LABELS = 3                             # Number of labels\n",
    "BATCH_SIZE = 16                             # Size of batch\n",
    "HEIGHT = 224                                 # Height of input image\n",
    "WIDTH = 224                                  # Width of input image\n",
    "N_CHANNEL = 3                               # Number of channels\n",
    "OUTPUT_DIM = 3                             # Number of output dimension\n",
    "\n",
    "# Set training hyperparameters\n",
    "NUM_EPOCH = 100                             # Number of epoch to train\n",
    "LR = 0.0001                                 # Learning rate\n",
    "\n",
    "INPUT_SHAPE = (HEIGHT, WIDTH, N_CHANNEL)  # Input shape of model\n",
    "IMG_SHAPE = (HEIGHT, WIDTH, N_CHANNEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7IHv1efbIfUr",
    "outputId": "1456838e-6cc3-42fc-8361-6aaf1741d4d4"
   },
   "outputs": [],
   "source": [
    "# Convert the labels\n",
    "from tensorflow import keras\n",
    "labels_train_cat = keras.utils.to_categorical(labels_train, NUM_LABELS)\n",
    "labels_test_cat = keras.utils.to_categorical(labels_test, NUM_LABELS)\n",
    "labels_val_cat = keras.utils.to_categorical(labels_val, NUM_LABELS)\n",
    "all_labels = np.concatenate((labels_train, labels_test, labels_val), axis=0)\n",
    "label_names = np.unique(labels_val)\n",
    "print(label_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "id": "sTTjw748J4c5",
    "outputId": "4ef203b1-bfd2-449a-d115-a64412bbe469"
   },
   "outputs": [],
   "source": [
    "# Plot a few images to check if the labels make sense\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(9, 9))\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "for n in range(9):\n",
    "    i = np.random.randint(0, len(imgs_train), 1)\n",
    "    ax = plt.subplot(3, 3, n+1)\n",
    "    plt.imshow(imgs_train[i[0]])\n",
    "    plt.title('Label: ' + str(labels_train[i[0]]))\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wL1HG_vYFtCe"
   },
   "source": [
    "##Task 1\n",
    "CS5331 your task 1 goes here\n",
    "The first task will require you to train a deep-learning model to classify BUSI images. The training, validation, and testing datasets are already given to you. For full marks, the classification test accuracy is expected to be above 85%. Further, you should not have an overfitted model. This will look like a model you already built for a previous assignment, and if you recognize it and want to use it, feel free to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4YLEm3B2N-Y1"
   },
   "outputs": [],
   "source": [
    "## Impliment your model for task 1, use whatever steps you want as long as you meet the requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fx6h18PwSczp"
   },
   "outputs": [],
   "source": [
    "#Evaluate your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-C80okDEGPTt"
   },
   "source": [
    "##Task 2\n",
    "\n",
    "CS5331 here is your task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukavG-PkGV8u"
   },
   "source": [
    "# Code given to you for analysis/modification\n",
    "1.\tAnswer the following questions for the implemented attack.\n",
    "\n",
    "    a.\tWhat type of modifications to images are implemented? What each one of them is doing?\n",
    "\n",
    "    b.\tWhat does the poison_dataset do? What does it return? Be sure to have details here.\n",
    "2.\tImplementation. Implement poison_dataset function that takes clean images, clean labels, percentage of poisoning, and the poisoning function. The function should return 4 arrays, including a Boolean if the sample is poisoned or not, the sample, the label for that sample, and the original dataset label for that sample. The provided notebook is your guide; however, there are changes that you need to make.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2BZADe0k5RlU"
   },
   "outputs": [],
   "source": [
    "def add_modification(x):\n",
    "  if BACKDOOR_TYPE == 'pattern':\n",
    "      return add_pattern_bd(x, pixel_value=max_val)\n",
    "  elif BACKDOOR_TYPE == 'pixel':\n",
    "      return add_single_bd(x, pixel_value=max_val)\n",
    "  elif BACKDOOR_TYPE == 'image':\n",
    "      return insert_image(x, backdoor_path='../utils/data/backdoors/alert.png', size=(10,10))\n",
    "  else:\n",
    "      raise(\"Unknown backdoor type\")\n",
    "\n",
    "def add_pattern_bd(x: np.ndarray, distance: int = 2, pixel_value: int = 1) -> np.ndarray:\n",
    "  \"\"\"\n",
    "  Augments a matrix by setting a checkboard-like pattern of values some `distance` away from the bottom-right\n",
    "  edge to 1. Works for single images or a batch of images.\n",
    "  :param x: N X W X H matrix or W X H matrix or N X W X H X C matrix, pixels will ne added to all channels\n",
    "  :param distance: Distance from bottom-right walls.\n",
    "  :param pixel_value: Value used to replace the entries of the image matrix.\n",
    "  :return: Backdoored image.\n",
    "  \"\"\"\n",
    "  x = np.array(x)\n",
    "  shape = x.shape\n",
    "  if len(shape) == 4:\n",
    "    width, height = x.shape[1:3]\n",
    "    x[:, width - distance -1, height - distance -1, :] = pixel_value\n",
    "    x[:, width - distance -1, height - distance - 3, :] = pixel_value\n",
    "    x[:, width - distance -1, height - distance - 5, :] = pixel_value\n",
    "    x[:, width - distance -1, height - distance - 7, :] = pixel_value\n",
    "    x[:, width - distance - 3, height - distance -1, :] = pixel_value\n",
    "    x[:, width - distance - 5, height - distance -1, :] = pixel_value\n",
    "    x[:, width - distance - 7, height - distance -1, :] = pixel_value\n",
    "    x[:, width - distance - 2, height - distance - 2, :] = pixel_value\n",
    "    x[:, width - distance - 4, height - distance - 2, :] = pixel_value\n",
    "    x[:, width - distance - 6, height - distance - 2, :] = pixel_value\n",
    "    x[:, width - distance - 2, height - distance - 4, :] = pixel_value\n",
    "    x[:, width - distance - 2, height - distance - 6, :] = pixel_value\n",
    "    x[:, width - distance - 3, height - distance - 3, :] = pixel_value\n",
    "    x[:, width - distance - 3, height - distance - 5, :] = pixel_value\n",
    "    x[:, width - distance - 5, height - distance - 3, :] = pixel_value\n",
    "    x[:, width - distance - 4, height - distance - 4, :] = pixel_value\n",
    "\n",
    "  elif len(shape) == 3:\n",
    "    width, height = x.shape[1:]\n",
    "    x[:, width - distance, height - distance] = pixel_value\n",
    "    x[:, width - distance - 1, height - distance - 1] = pixel_value\n",
    "    x[:, width - distance, height - distance - 2] = pixel_value\n",
    "    x[:, width - distance - 2, height - distance] = pixel_value\n",
    "  elif len(shape) == 2:\n",
    "    width, height = x.shape\n",
    "    x[width - distance, height - distance] = pixel_value\n",
    "    x[width - distance - 1, height - distance - 1] = pixel_value\n",
    "    x[width - distance, height - distance - 2] = pixel_value\n",
    "    x[width - distance - 2, height - distance] = pixel_value\n",
    "  else:\n",
    "    raise ValueError(\"Invalid array shape: \" + str(shape))\n",
    "  return x\n",
    "\n",
    "def poison_dataset(x_clean, y_clean, percent_poison, poison_func):\n",
    "  #Your Implimentation here. Here is what you should return\n",
    "  return is_poison, x_poison, y_poison, y_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CtBCWSjE4sWh"
   },
   "outputs": [],
   "source": [
    "BACKDOOR_TYPE = \"pattern\" ##You may change it to others and see the performance if you wish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7ce2EvnHBw7"
   },
   "source": [
    "# poison the daataset\n",
    "3.\t Create poisoned training images using BUSI imagesâ€™ training and validation sets. Select the percentage of poisoned images to be 20%. You may choose a different value if you wish to.\n",
    "4.\tPlot at least 9 images with the applied backdoor pattern and display the target label for the images and if they are poisoned or not.\n",
    "5. Create a poisoned test dataset by adding poisoned images to the original test dataset of 156 images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "39G4VgRC4wAZ"
   },
   "outputs": [],
   "source": [
    "#poison the training\n",
    "\n",
    "#Print the shape of the training to make sure you are correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B4F8aBrj6K65"
   },
   "outputs": [],
   "source": [
    "# Plot a few images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ctBQYai6Ofg"
   },
   "outputs": [],
   "source": [
    "#poison the test images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jYosRivJj-y"
   },
   "source": [
    "#Train on poisened images\n",
    "6.\tImplementation. Train a poisoned model on the poisoned set of images. You can try training for a few epochs (maybe around 15 epochs), but if the attack success rate is low, you can retrain the model for longer. Estimated time on GPU: between 3 and 10 minutes.\n",
    "\n",
    "7.\tEvaluate the poisoned model on clean test images and report the classification accuracy. Fill in Table 2. The classification accuracy on clean test images should be high and not significantly lower than the original accuracy of the model. For full marks, the accuracy should be at least 80%.\n",
    "\n",
    "\n",
    "8.\tPlot at least 9 clean images, and show the true, predicted class label, and if the image is poisoned or not. The figure below is an example without the poisoned image label. Make sure to add that.\n",
    "\n",
    "10. Evaluate the model on poisoned test images. Report how many of the poisoned benign images were classified as malignant images. For full marks, the attack success rate should be above 70%.\n",
    "\n",
    "11.\tPlot at least 9 poisoned images, and show the target predicted class label, and if the image is poisoned or not.\n",
    "\n",
    "13. Plot at least 12 poisoned random images from all, and show the target predicted class label, and if the image is poisoned or not. An example is shown below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vjRN-NCT6doJ"
   },
   "outputs": [],
   "source": [
    "# Shuffle training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AbgxvveR6i3Z"
   },
   "outputs": [],
   "source": [
    "# Fit your ART classifier with the correct training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZX554P9i7nio"
   },
   "outputs": [],
   "source": [
    "#Evaluate on Clean images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gEFX76Uu7xW9"
   },
   "outputs": [],
   "source": [
    "#Plot clean images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEWx9F9bLCzC"
   },
   "outputs": [],
   "source": [
    "#Evaluate on poisoned images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IlEQE-a_8FQq"
   },
   "outputs": [],
   "source": [
    "#plot poisoned images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RDlqy1i98JSo"
   },
   "outputs": [],
   "source": [
    "#plot a mix of poisoned and not poisened images"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
