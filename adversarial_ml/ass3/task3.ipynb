{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXS34BaP4hFp"
   },
   "source": [
    "#Use a proper tensorflow version\n",
    "Our model was build on TF2.14 and it does cause some compatibility issues with TF2.17 so make sure you use the right version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AVrdszHO4W8T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "#Check tf version\n",
    "import tensorflow as tf\n",
    "#print(tf.__version__)\n",
    "\n",
    "#The following force you to use tensorflow 2.14 but you need to restart. You may comment it if you know you are using 2.14\n",
    "##Make sure you down grade!! otherwise, some part will fail due to compatibility.\n",
    "#!pip3 install --upgrade tensorflow==2.14.0\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHOSNj1B41Mp"
   },
   "source": [
    "#Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FgNawstG47ip"
   },
   "outputs": [],
   "source": [
    "# mount google drive on your runtime using and authorization code.\n",
    "# more details here: https://colab.research.google.com/notebooks/io.ipynb\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tJGFrqJL48eh"
   },
   "outputs": [],
   "source": [
    "#Set directories correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "T6NoHeZj5C5N"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Path to the directory containing the project files (CHANGE THIS PATH TO THE DIRECTORY ON YOUR COMPUTER)\n",
    "PROJECT_ROOT_DIR = os.getcwd() + '/'\n",
    "\n",
    "# Path to the directory containing the dataset relative to project file\n",
    "DATA_DIR = './GTSRB_dataset(2)/GTSRB_dataset/'\n",
    "\n",
    "#path to the directory you want to use for saving models relative to the project file\n",
    "MODEL_DIR = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CR4Qlshh5DrN"
   },
   "outputs": [],
   "source": [
    "# Funciton for loading the dataset\n",
    "# Code from advml-traffic-sign (https://github.com/inspire-group/advml-traffic-sign)\n",
    "def load_dataset_GTSRB(n_channel=3, train_file_name=None):\n",
    "    \"\"\"\n",
    "    Load GTSRB data as a (datasize) x (channels) x (height) x (width) numpy\n",
    "    matrix. Each pixel is rescaled to the range [0,1].\n",
    "    \"\"\"\n",
    "\n",
    "    def load_pickled_data(file, columns):\n",
    "        \"\"\"\n",
    "        Loads pickled training and test data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        file    : string\n",
    "                          Name of the pickle file.\n",
    "        columns : list of strings\n",
    "                          List of columns in pickled data we're interested in.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A tuple of datasets for given columns.\n",
    "        \"\"\"\n",
    "\n",
    "        with open(file, mode='rb') as f:\n",
    "            dataset = pickle.load(f)\n",
    "        return tuple(map(lambda c: dataset[c], columns))\n",
    "\n",
    "    def preprocess(x, n_channel):\n",
    "        \"\"\"\n",
    "        Preprocess dataset: turn images into grayscale if specified, normalize\n",
    "        input space to [0,1], reshape array to appropriate shape for NN model\n",
    "        \"\"\"\n",
    "\n",
    "        if n_channel == 3:\n",
    "            # Scale features to be in [0, 1]\n",
    "            x = (x / 255.).astype(np.float32)\n",
    "        else:\n",
    "            # Convert to grayscale, e.g. single Y channel\n",
    "            x = 0.299 * x[:, :, :, 0] + 0.587 * x[:, :, :, 1] + \\\n",
    "                0.114 * x[:, :, :, 2]\n",
    "            # Scale features to be in [0, 1]\n",
    "            x = (x / 255.).astype(np.float32)\n",
    "            x = x[:, :, :, np.newaxis]\n",
    "        return x\n",
    "\n",
    "    # Load pickle dataset\n",
    "    if train_file_name is None:\n",
    "        x_train, y_train = load_pickled_data(\n",
    "            PROJECT_ROOT_DIR + DATA_DIR + 'train.p', ['features', 'labels'])\n",
    "    else:\n",
    "        x_train, y_train = load_pickled_data(\n",
    "            PROJECT_ROOT_DIR + DATA_DIR + train_file_name, ['features', 'labels'])\n",
    "    x_val, y_val = load_pickled_data(\n",
    "        PROJECT_ROOT_DIR + DATA_DIR + 'valid.p', ['features', 'labels'])\n",
    "    x_test, y_test = load_pickled_data(\n",
    "        PROJECT_ROOT_DIR + DATA_DIR + 'test.p', ['features', 'labels'])\n",
    "\n",
    "    # Preprocess loaded data\n",
    "    x_train = preprocess(x_train, n_channel)\n",
    "    x_val = preprocess(x_val, n_channel)\n",
    "    x_test = preprocess(x_test, n_channel)\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "BREhI6Eu5F2Q"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "# Load the images and labels. These images are RGB so we have 3 channels\n",
    "imgs_train, labels_train, imgs_val, labels_val, imgs_test, labels_test = load_dataset_GTSRB(n_channel=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8jMLxK1-5Idu"
   },
   "source": [
    "#Load the built model from Assignment 1 (Already on blackboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dWHxthXD5Rcg"
   },
   "outputs": [],
   "source": [
    "## Load the saved the model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "\n",
    "#load our already trained model\n",
    "# Your earlier directories should change to match this one\n",
    "#You should be able to load the model once trained. The following line is used for that.\n",
    "model = load_model(MODEL_DIR +'VGG_best(1).h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1YlYwHF5dkA"
   },
   "source": [
    "#Some constants that you might need\n",
    "It is not neccessary that you will use all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "g1T2kO385c4z"
   },
   "outputs": [],
   "source": [
    "# Set constants (GTSRB)\n",
    "NUM_LABELS = 43                             # Number of labels or classes for classification\n",
    "BATCH_SIZE = 128                            # Size of batch\n",
    "HEIGHT = 32                                 # Height of input image\n",
    "WIDTH = 32                                  # Width of input image\n",
    "N_CHANNEL = 3                               # Number of channels\n",
    "OUTPUT_DIM = 43                             # Number of output dimension\n",
    "\n",
    "# Set training hyperparameters\n",
    "NUM_EPOCH = 50                            # Number of epoch to train\n",
    "LR = 0.0002                                 # Learning rate\n",
    "RBW = True #restore best weights\n",
    "PATIENCE = 5# how many epochs between improvements\n",
    "sample_size = 100\n",
    "alpha = 0.001\n",
    "INPUT_SHAPE = (HEIGHT, WIDTH, N_CHANNEL)  # Input shape of model\n",
    "IMG_SHAPE = (HEIGHT, WIDTH, N_CHANNEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "biWtvVpy5zzK"
   },
   "source": [
    "# setting up labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WJMiQebv5nvV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels train shape: (34799,)\n",
      "Labels train catagorical shape: (34799, 43)\n",
      "\n",
      "Labels Adver shape: (500,)\n",
      "Labels Adver catagorical shape: (500, 43)\n",
      "Imgs Adver shape: (500, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#Convert the labels to one-hot encoding (to input to the models)\n",
    "\n",
    "#Use the following sub-test dataset for your certified training\n",
    "imgs_sub_test = imgs_test[0:500,:,:,:].copy()\n",
    "labels_adv = labels_test[0:500].copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "labels_train_cat = to_categorical(labels_train, NUM_LABELS)\n",
    "labels_test_cat = to_categorical(labels_test, NUM_LABELS)\n",
    "labels_val_cat = to_categorical(labels_val, NUM_LABELS)\n",
    "\n",
    "#for testing adversarial inputs\n",
    "labels_adv_cat = to_categorical(labels_adv,NUM_LABELS)\n",
    "\n",
    "print('Labels train shape: {}'.format(labels_train.shape))\n",
    "print('Labels train catagorical shape: {}\\n'.format(labels_train_cat.shape))\n",
    "print('Labels Adver shape: {}'.format(labels_adv.shape))\n",
    "print('Labels Adver catagorical shape: {}'.format(labels_adv_cat.shape))\n",
    "\n",
    "print('Imgs Adver shape: {}'.format(imgs_sub_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEzJaepK6Bhl"
   },
   "source": [
    "#Install ART if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uHszEWtc5-dg"
   },
   "outputs": [],
   "source": [
    "#Install ART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQoee7X36RA-"
   },
   "source": [
    "#Some imports.\n",
    "You might need more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "g7WT4z2n6VTx"
   },
   "outputs": [],
   "source": [
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_n05hfxU-aNp"
   },
   "source": [
    "##Task 3\n",
    "Let's do another privacy attack. This time, it is a “shadow models” attack, discussed in class. [This notebook](https://github.com/Trusted-AI/adversarial-robustness-toolbox/blob/main/notebooks/attack_membership_inference_shadow_models.ipynb) will be your guide. You are going to use ART again, and here are a few steps to follow:\n",
    "\n",
    "1-\tBuild the shadow models based on the numbers provided below. Set the training ratio for them to 0.5.\n",
    "\n",
    "2-\tMeasure the accuracies for them (use validation accuracy as a measure)\n",
    "\n",
    "3-\tBuild the attack model. You can build any binary classifier. You are suggested to use a random forest classifier for simplicity.\n",
    "\n",
    "4-\tEvaluate your attack models for members and non-members (the evaluation data is already given to you).\n",
    "\n",
    "5-\tCalculate the precision and recall of your attack model.\n",
    "\n",
    "Your changing parameter in this task is the number of shadow models. You will set it to 1,2 and 5. Please note the needed metrics so you can plan your code accordingly.\n",
    "\n",
    "#Note on the implementation:\n",
    "Our implementation will look strange. Shadow models will require lots and lots of data. Thus, in a general setup, researchers use 80% of the data for shadow models, and only 20% is for training/testing/validation. However, given that we are using a model already built from Assignment 1, we cannot use this general setup. Thus, our shadow models' data will concatenate training and testing while the validation will be left out to test performance accuracy. To evaluate the attack, we generated a separate dataset that is taken from training and testing. You will need to locate and work with that data. In general, your attack results won't be good due to the above design, but the idea is that you should analyze it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svWAKJzo-xiC"
   },
   "source": [
    "# Data for evaluating the attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "O2Br_zjj-WOK"
   },
   "outputs": [],
   "source": [
    "# Data for evaluating the attack.\n",
    "from numpy.random import choice\n",
    "n_sample_train = 3000\n",
    "eval_data_idx=choice(len(imgs_train), n_sample_train)\n",
    "members_samples, members_labels= imgs_train[eval_data_idx], labels_train_cat[eval_data_idx]\n",
    "n_sample_train = 3000\n",
    "eval_data_idx=choice(len(imgs_test), n_sample_train)\n",
    "non_members_samples, non_members_labels= imgs_test[eval_data_idx], labels_test_cat[eval_data_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwAwK5Qn-2Zf"
   },
   "source": [
    "#Impliment your attack based on the above steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_precision_recall(predicted, actual, positive_value=1):\n",
    "    score = 0  # both predicted and actual are positive\n",
    "    num_positive_predicted = 0  # predicted positive\n",
    "    num_positive_actual = 0  # actual positive\n",
    "    for i in range(len(predicted)):\n",
    "        if predicted[i] == positive_value:\n",
    "            num_positive_predicted += 1\n",
    "        if actual[i] == positive_value:\n",
    "            num_positive_actual += 1\n",
    "        if predicted[i] == actual[i]:\n",
    "            if predicted[i] == positive_value:\n",
    "                score += 1\n",
    "\n",
    "    if num_positive_predicted == 0:\n",
    "        precision = 1\n",
    "    else:\n",
    "        precision = score / num_positive_predicted  # the fraction of predicted “Yes” responses that are correct\n",
    "    if num_positive_actual == 0:\n",
    "        recall = 1\n",
    "    else:\n",
    "        recall = score / num_positive_actual  # the fraction of “Yes” responses that are predicted correctly\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34799, 32, 32, 3) (34799,)\n"
     ]
    }
   ],
   "source": [
    "print(imgs_train.shape,labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model accuracy: 0.7534441805225653\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "x_target_train = members_samples\n",
    "y_target_train = members_labels\n",
    "x_target_test = non_members_samples\n",
    "y_target_test = non_members_labels\n",
    "x_target_train= x_target_train.reshape(x_target_train.shape[0], -1)\n",
    "y_target_train = np.argmax(y_target_train, axis=1)\n",
    "x_target_test= x_target_test.reshape(x_target_test.shape[0], -1)\n",
    "y_target_test= np.argmax(y_target_test, axis=1)\n",
    "'''\n",
    "x_target_train = imgs_train\n",
    "y_target_train = labels_train\n",
    "x_target_test = imgs_test\n",
    "y_target_test = labels_test\n",
    "x_target_train= x_target_train.reshape(x_target_train.shape[0], -1)\n",
    "#y_target_train = np.argmax(y_target_train, axis=1)\n",
    "x_target_test= x_target_test.reshape(x_target_test.shape[0], -1)\n",
    "#y_target_test= np.argmax(y_target_test, axis=1)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from art.estimators.classification.scikitlearn import ScikitlearnRandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(x_target_train, y_target_train)\n",
    "art_classifier = ScikitlearnRandomForestClassifier(model)\n",
    "print('Base model accuracy:', model.score(x_target_test, y_target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5598639455782313]\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------ Shadow Models= 1 ------------------------------------------\n",
    "from art.attacks.inference.membership_inference import ShadowModels\n",
    "from art.utils import to_categorical\n",
    "x_shadow = imgs_test\n",
    "y_shadow = to_categorical(labels_test)\n",
    "x_shadow = x_shadow.reshape(x_shadow.shape[0], -1)\n",
    "y_shadow = to_categorical(np.argmax(y_shadow, axis=1))\n",
    "shadow_models = ShadowModels(art_classifier, num_shadow_models=1)\n",
    "shadow_dataset = shadow_models.generate_shadow_dataset(x_shadow, y_shadow)\n",
    "(member_x, member_y, member_predictions), (nonmember_x, nonmember_y, nonmember_predictions) = shadow_dataset\n",
    "print([sm.model.score(imgs_val.reshape(imgs_val.shape[0], -1), labels_val) for sm in shadow_models.get_shadow_models()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack Member Acc: 0.919767809419811\n",
      "Attack Non-Member Acc: 0.8453681710213776\n",
      "Attack Accuracy: 0.899955723291657\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.inference.membership_inference import MembershipInferenceBlackBox\n",
    "attack = MembershipInferenceBlackBox(art_classifier, attack_model_type=\"rf\")\n",
    "attack.fit(member_x, member_y, nonmember_x, nonmember_y, member_predictions, nonmember_predictions)\n",
    "member_infer = attack.infer(x_target_train, y_target_train)\n",
    "nonmember_infer = attack.infer(x_target_test, y_target_test)\n",
    "member_acc = np.sum(member_infer) / len(x_target_train)\n",
    "nonmember_acc = 1 - (np.sum(nonmember_infer) / len(x_target_test))\n",
    "acc = (member_acc * len(x_target_train) + nonmember_acc * len(x_target_test)) / (len(x_target_train) + len(x_target_test))\n",
    "print('Attack Member Acc:', member_acc)\n",
    "print('Attack Non-Member Acc:', nonmember_acc)\n",
    "print('Attack Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack Member Acc: 0.9341360383919078\n",
      "Attack Non-Member Acc: 0.792874109263658\n",
      "Attack Accuracy: 0.8965190073583672\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.inference.membership_inference import MembershipInferenceBlackBox\n",
    "attack = MembershipInferenceBlackBox(art_classifier, attack_model_type=\"rf\")\n",
    "attack.fit(member_x, member_y, nonmember_x, nonmember_y, member_predictions, nonmember_predictions)\n",
    "member_infer = attack.infer(x_target_train, y_target_train)\n",
    "nonmember_infer = attack.infer(x_target_test, y_target_test)\n",
    "member_acc = np.sum(member_infer) / len(x_target_train)\n",
    "nonmember_acc = 1 - (np.sum(nonmember_infer) / len(x_target_test))\n",
    "acc = (member_acc * len(x_target_train) + nonmember_acc * len(x_target_test)) / (len(x_target_train) + len(x_target_test))\n",
    "print('Attack Member Acc:', member_acc)\n",
    "print('Attack Non-Member Acc:', nonmember_acc)\n",
    "print('Attack Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9255188907553455, 0.9341360383919078)\n"
     ]
    }
   ],
   "source": [
    "print(calc_precision_recall(np.concatenate((member_infer, nonmember_infer)),\n",
    "                            np.concatenate((np.ones(len(member_infer)), np.zeros(len(nonmember_infer))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5340136054421769, 0.5410430839002267, 0.5446712018140589]\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------ Shadow Models= 3 ------------------------------------------\n",
    "from art.attacks.inference.membership_inference import ShadowModels\n",
    "from art.utils import to_categorical\n",
    "x_shadow = imgs_test\n",
    "y_shadow = to_categorical(labels_test)\n",
    "x_shadow = x_shadow.reshape(x_shadow.shape[0], -1)\n",
    "y_shadow = to_categorical(np.argmax(y_shadow, axis=1))\n",
    "shadow_models = ShadowModels(art_classifier, num_shadow_models=3)\n",
    "shadow_dataset = shadow_models.generate_shadow_dataset(x_shadow, y_shadow)\n",
    "(member_x, member_y, member_predictions), (nonmember_x, nonmember_y, nonmember_predictions) = shadow_dataset\n",
    "print([sm.model.score(imgs_val.reshape(imgs_val.shape[0], -1), labels_val) for sm in shadow_models.get_shadow_models()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack Member Acc: 0.9299117790741114\n",
      "Attack Non-Member Acc: 0.8047505938242281\n",
      "Attack Accuracy: 0.8965822597988572\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.inference.membership_inference import MembershipInferenceBlackBox\n",
    "attack = MembershipInferenceBlackBox(art_classifier, attack_model_type=\"rf\")\n",
    "attack.fit(member_x, member_y, nonmember_x, nonmember_y, member_predictions, nonmember_predictions)\n",
    "member_infer = attack.infer(x_target_train, y_target_train)\n",
    "nonmember_infer = attack.infer(x_target_test, y_target_test)\n",
    "member_acc = np.sum(member_infer) / len(x_target_train)\n",
    "nonmember_acc = 1 - np.sum(nonmember_infer) / len(x_target_test)\n",
    "acc = (member_acc * len(x_target_train) + nonmember_acc * len(x_target_test)) / (len(x_target_train) + len(x_target_test))\n",
    "print('Attack Member Acc:', member_acc)\n",
    "print('Attack Non-Member Acc:', nonmember_acc)\n",
    "print('Attack Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9291908344340435, 0.9299117790741114)\n"
     ]
    }
   ],
   "source": [
    "print(calc_precision_recall(np.concatenate((member_infer, nonmember_infer)),\n",
    "                            np.concatenate((np.ones(len(member_infer)), np.zeros(len(nonmember_infer))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5489795918367347, 0.5498866213151927, 0.5458049886621316, 0.5505668934240363, 0.5648526077097505]\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------ Shadow Models= 5 ------------------------------------------\n",
    "from art.attacks.inference.membership_inference import ShadowModels\n",
    "from art.utils import to_categorical\n",
    "x_shadow = imgs_test\n",
    "y_shadow = to_categorical(labels_test)\n",
    "x_shadow = x_shadow.reshape(x_shadow.shape[0], -1)\n",
    "y_shadow = to_categorical(np.argmax(y_shadow, axis=1))\n",
    "shadow_models = ShadowModels(art_classifier, num_shadow_models=5)\n",
    "shadow_dataset = shadow_models.generate_shadow_dataset(x_shadow, y_shadow)\n",
    "(member_x, member_y, member_predictions), (nonmember_x, nonmember_y, nonmember_predictions) = shadow_dataset\n",
    "print([sm.model.score(imgs_val.reshape(imgs_val.shape[0], -1), labels_val) for sm in shadow_models.get_shadow_models()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack Member Acc: 0.9298255697002787\n",
      "Attack Non-Member Acc: 0.8157561361836896\n",
      "Attack Accuracy: 0.899449703767737\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.inference.membership_inference import MembershipInferenceBlackBox\n",
    "attack = MembershipInferenceBlackBox(art_classifier, attack_model_type=\"rf\")\n",
    "attack.fit(member_x, member_y, nonmember_x, nonmember_y, member_predictions, nonmember_predictions)\n",
    "member_infer = attack.infer(x_target_train, y_target_train)\n",
    "nonmember_infer = attack.infer(x_target_test, y_target_test)\n",
    "member_acc = np.sum(member_infer) / len(x_target_train)\n",
    "nonmember_acc = 1 - np.sum(nonmember_infer) / len(x_target_test)\n",
    "acc = (member_acc * len(x_target_train) + nonmember_acc * len(x_target_test)) / (len(x_target_train) + len(x_target_test))\n",
    "print('Attack Member Acc:', member_acc)\n",
    "print('Attack Non-Member Acc:', nonmember_acc)\n",
    "print('Attack Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9329085457271364, 0.9298255697002787)\n"
     ]
    }
   ],
   "source": [
    "print(calc_precision_recall(np.concatenate((member_infer, nonmember_infer)),\n",
    "                            np.concatenate((np.ones(len(member_infer)), np.zeros(len(nonmember_infer))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
