{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Gradient Based Adversarial Attacks\n",
    "\n",
    "Adversarial perturbations are small changes to an machine learning model's input with the goal of pushing that input over the model's decision boundary. Visualizing decision boundaries and understanding concepts from gradient-based adversarial attacks can be challenging in high dimensional spaces. This homework is adapted from the notebook  https://github.com/adrian-botta/understanding_adversarial_examples/blob/master/adversarial_examples_logistic_regression.ipynb\n",
    "\n",
    "\n",
    "We'll start with a simple classification example with a subset of the Iris dataset - (inspired from: \n",
    "https://medium.com/@martinpella/logistic-regression-from-scratch-in-python-124c5636b8ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "sns.set(style=\"white\")\n",
    "figure_size = [11,7.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]\n",
    "y = (iris.target != 0) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.asarray(['r']*len(y))\n",
    "colors[y==1] = 'b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(figure_size[0], figure_size[1]))\n",
    "ax.scatter(X[:,0], X[::, 1], c=colors, edgecolor=\"white\", linewidth=1)\n",
    "plt.xlabel(\"X1\"),plt.ylabel(\"X2\")\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label='Class: 0',\n",
    "                          markerfacecolor='r', markersize=5),\n",
    "                   Line2D([0], [0], marker='o', color='w', label='Class: 1',\n",
    "                          markerfacecolor='b', markersize=5)]\n",
    "ax.legend(handles=legend_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we have a scatter plot showing two classes in the sample dataset. We will use a logistic regression as our classifier and can use its coefficients to draw its decision boundary and create a probability distribution of the class of a data point given the X1 & X2 variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll fit a logistic regression to X values by changing Theta\n",
    "$$g(x) = \\frac{1}{1+\\exp(-\\theta^Tx)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression().fit(X, y)\n",
    "w = clf.coef_[0]\n",
    "a = -w[0] / w[1]\n",
    "xx_mod = np.linspace(3.5, 8.4)\n",
    "yy_mod = a * xx_mod - (clf.intercept_[0]) / w[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(figure_size[0], figure_size[1]))\n",
    "ax.scatter(X[:,0], X[:, 1], c=colors,edgecolor=\"white\", linewidth=1)\n",
    "plt.xlabel(\"X1\"),plt.ylabel(\"X2\")\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label='Class: 0',\n",
    "                          markerfacecolor='r', markersize=5),\n",
    "                   Line2D([0], [0], marker='o', color='w', label='Class: 1',\n",
    "                          markerfacecolor='b', markersize=5),\n",
    "                   Line2D([0], [0], marker='None', color='black', label='Decision Boundary',\n",
    "                          markerfacecolor='black', markersize=5)]\n",
    "ax.legend(handles=legend_elements)\n",
    "ax.plot(xx_mod, yy_mod, 'k-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = np.mgrid[3.5:8.5:.01, 1.5:5.5:.01]\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "probs = clf.predict_proba(grid)[:, 1].reshape(xx.shape)\n",
    "f, ax = plt.subplots(figsize=(figure_size[0], figure_size[1]))\n",
    "contour = ax.contourf(xx, yy, probs, 25, cmap=\"RdBu\",\n",
    "                      vmin=0, vmax=1)\n",
    "ax_c = f.colorbar(contour)\n",
    "ax_c.set_label(\"$P(y = 1)$\")\n",
    "ax_c.set_ticks([0, .25, .5, .75, 1])\n",
    "\n",
    "ax.scatter(X[:,0], X[::, 1], c=y, s=50,\n",
    "           cmap=\"RdBu\", vmin=-.2, vmax=1.2,\n",
    "           edgecolor=\"white\", linewidth=1)\n",
    "\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label='Class: 0',\n",
    "                          markerfacecolor='r', markersize=5),\n",
    "                   Line2D([0], [0], marker='o', color='w', label='Class: 1',\n",
    "                          markerfacecolor='b', markersize=5),\n",
    "                   Line2D([0], [0], marker='None', color='black', label='Decision Boundary',\n",
    "                          markerfacecolor='black', markersize=5)]\n",
    "legend = ax.legend(handles=legend_elements, frameon=True, framealpha=1)\n",
    "legend.get_frame().set_facecolor('white')\n",
    "plt.xlabel(\"X1\"),plt.ylabel(\"X2\")\n",
    "ax.plot(xx_mod, yy_mod, 'k-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we train our machine learning models, we're defining a loss function that we then aim to minimize\n",
    "$$J(\\theta) = \\frac{1}{m}\\sum_{i = 1}^M \\log(1+\\exp(-y_i \\theta^Tx_i)),$$\n",
    "where $y_i$ is the label of the ith sample, and $x_i$ is a two-dimensional vector representing the feature of the ith sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = clf.coef_\n",
    "def loss(theta, X, y):\n",
    "\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This is our model's training loss:\", loss(theta, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To update the values of theta, we take the partial derivative of our loss function with respect to (w.r.t) theta. The partial derivative tells us how to change the values of theta to change the loss\n",
    "$$\\frac{\\partial J(\\theta)}{\\partial \\theta} = ??$$ (please evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_wrt_theta(theta, X, y):\n",
    "    \"\"\"\n",
    "    Compute the gradient of logistic loss with respect to theta.\n",
    "\n",
    "    Args:\n",
    "        theta: (1,2) numpy array, parameter vector\n",
    "        X: (m, 2) numpy array, input features\n",
    "        y: (m,) numpy array, labels \n",
    "\n",
    "    Returns:\n",
    "        grad: (1,2) numpy array, gradient vector\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Grads w.r.t. Theta\",gradient_wrt_theta(theta, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With gradient-based adversarial attacks, we want to use the gradients to determine how to change X such that the loss increases (or decreases with a targeted attack). Implement the fast gradient sign method-based adversarial sample generation, i.e., \n",
    "$$X' = X + \\eta = X + \\epsilon\\times \\mathrm{Sign}\\left( \\frac{\\partial J(\\theta)}{\\partial X} \\right)$$ (please evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sign_gradient_wrt_X(theta, y):\n",
    "\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Creating the adversarial perturbation ***\n",
    "\n",
    "To create the adversarial X values. Finish the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.5\n",
    "sign_dX = sign_gradient_wrt_X(theta, y)\n",
    "X_advs = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(figure_size[0], figure_size[1]))\n",
    "colors = np.asarray(['gray']*len(y))\n",
    "ax.scatter(X[:50,0], X[:50, 1], c='grey', s=50,#y[:1], s=50,\n",
    "           cmap=\"RdBu\", vmin=-.2, vmax=1.2,\n",
    "           edgecolor=\"white\", linewidth=1)\n",
    "ax.scatter(X[:1,0], X[:1, 1], c='red', s=50,\n",
    "           cmap=\"RdBu\", vmin=-.2, vmax=1.2,\n",
    "           edgecolor=\"black\", linewidth=1)\n",
    "ax.scatter(X_advs[:1,0], X_advs[:1, 1], c='blue', s=50,\n",
    "           cmap=\"RdBu\", vmin=-.2, vmax=1.2,\n",
    "           edgecolor=\"black\", linewidth=1)\n",
    "plt.arrow(X[0,0], X[0,1], (X_advs[0,0]-X[0,0])*0.8, (X_advs[0,1]-X[0,1])*0.8,\n",
    "         head_width = 0.05, color=\"black\")\n",
    "ax.plot(xx_mod, yy_mod, 'k-')\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label='Class: 0',\n",
    "                          markerfacecolor='grey', markersize=5),\n",
    "                   Line2D([0], [0], marker='o', color='w', label='Original X', markeredgecolor = 'black',\n",
    "                          markeredgewidth=1, markerfacecolor='red', markersize=5),\n",
    "                   Line2D([0], [0], marker='o', color='w', label='Adversarial X', markeredgecolor = 'black',\n",
    "                          markeredgewidth=1, markerfacecolor='blue', markersize=5),\n",
    "                   Line2D([0], [0], marker='None', color='black', label='Decision Boundary',\n",
    "                          markerfacecolor='black', markersize=5)]\n",
    "ax.legend(handles= legend_elements)\n",
    "plt.xlabel(\"X1\"),plt.ylabel(\"X2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the figure above, we're able to see that we chose the correct step size (epsilon) to cross our victim model's decision boundary. In the figure below, we can see that this step size works for several points in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample = np.asarray([1,2,3,7,8,9,12,18,20,23,25,26,27,28,\n",
    "                     29,30,31,34,35,36,37,38,39,45,47,49])\n",
    "\n",
    "f, ax = plt.subplots(figsize=(figure_size[0], figure_size[1]))\n",
    "colors = np.asarray(['gray']*len(y))\n",
    "ax.scatter(X[:50,0], X[:50, 1], c=colors[:50], s=50,#y[:1], s=50,\n",
    "           cmap=\"RdBu\", vmin=-.2, vmax=1.2,\n",
    "           edgecolor=\"white\", linewidth=1)\n",
    "\n",
    "ax.scatter(X[sample,0], X[sample, 1], c='red', s=50,\n",
    "           cmap=\"RdBu\", vmin=-.2, vmax=1.2,\n",
    "           edgecolor=\"black\", linewidth=1)\n",
    "\n",
    "ax.scatter(X_advs[sample,0], X_advs[sample, 1], c='blue', s=50,\n",
    "           cmap=\"RdBu\", vmin=-.2, vmax=1.2,\n",
    "           edgecolor=\"black\", linewidth=1)\n",
    "\n",
    "for arr in sample:\n",
    "    plt.arrow(X[arr,0], X[arr,1], \n",
    "          (X_advs[arr,0]-X[arr,0])*0.80, \n",
    "          (X_advs[arr,1]-X[arr,1])*0.80,\n",
    "          head_width = 0.05, color=\"black\")\n",
    "\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label='Class: 0',\n",
    "                      markerfacecolor='grey', markersize=5),\n",
    "               Line2D([0], [0], marker='o', color='w', markeredgecolor = 'black', label='Original X',\n",
    "                      markeredgewidth = 1, markerfacecolor='red', markersize=5),\n",
    "               Line2D([0], [0], marker='o', color='w', markeredgecolor = 'black', label='Adversarial X',\n",
    "                      markeredgewidth = 1, markerfacecolor='blue', markersize=5),\n",
    "               Line2D([0], [0], marker='None', color='black', label='Decision Boundary',\n",
    "                      markerfacecolor='black', markersize=5)]\n",
    "ax.legend(handles= legend_elements)\n",
    "plt.xlabel(\"X1\"),plt.ylabel(\"X2\")\n",
    "ax.plot(xx_mod, yy_mod, 'k-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Checking predictions ***\n",
    "\n",
    "We can see that crossing the decision boundary indeed changed our model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"victim model predictions\", clf.predict(X_advs[sample]))\n",
    "print(\"original labels:        \", y[sample])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
